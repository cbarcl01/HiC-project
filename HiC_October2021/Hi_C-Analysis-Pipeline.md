HiC sequencing analysis pipeline
================
Charlotte Barclay
23/10/2021

## Introduction

This document includes instructions for set up and running of analysis
pipeline for chromosome scale assembly of Mnemiopsis leidyi through the
addition of HiC data.

### 1.1 Create conda environment

In order to run the analysis, we need to make sure the relevant software
is installed and packed. Using conda allows us too XXX

``` bash
#create environment with required parameters
conda create --prefix /arc/project/st-ssplotki-1/HiC_analysis python=2.7
source activate /arc/project/st-ssplotki-1/HiC_analysis

# add channels
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

# install software
conda install -c bioconda salsa2
```

Now the conda environment is set up, I need to prepare the environment
by including the relevant tools. To start the scaffolding, I will need
to map reads to the assembly using wither BWA or Bowtie2, however Salsa
requires a bed file as input therefore I need to install both:

  - BOWTIE2 or BWA
  - Bedtools

**Code to install bowtie and bedtools**

``` bash
#create environment with required add ons
conda install -c bioconda bowtie2
conda install -c bioconda bwa
conda install -c bioconda bedtools
```

Additionally I need a contig lengths file for input, for which I need to
run samtools

**Code to install samtools**

``` bash
conda install -c bioconda samtools
```

Finally, as HiC experiments can use different restriction enzymes - and
the enzyme frequency in the contigs is used to normalise HiC interaction
frequency in SALSA - I need to specify the restriction enzymes. To
specify multiple restriction enzymes these should be separated by a
\*\*comma, without space"". The restriction enzymes used were:

  - HinfI G^ANTC
  - MseI T^TAA
  - DdeI C^TNAG
  - DPNII ^GATC

### 1.2 Identify data

I need a reference genome dataset to align the HiC data too. In future
this will be the long read PacBio data generated by the lab. To test the
workflow I will use the existing ref dataset available here.

``` bash
pscp -P 22 C:\Users\cbarc\OneDrive\Documents\LAB_OriginsOfMulticellularity\Data\2021Sept_HiC_Raw\plotkin-mle_S3HiC_R2.fastq.gz cbarcl01@sockeye.arc.ubc.ca:/home/cbarcl01/21_Oct_HiC

pscp -P 22 C:\Users\cbarc\OneDrive\Documents\LAB_OriginsOfMulticellularity\Data\2021Sept_HiC_Raw\plotkin-mle_S3HiC_R1.fastq.gz cbarcl01@sockeye.arc.ubc.ca:/home/cbarcl01/21_Oct_HiC 
```

## 2.0 Prepare input files

As described in the introduction, the pipeline starts with alignment of
the data to the existing assembly.

### 2.1 Mapping Reads

To start the scaffolding, first step is to map reads to the assembly.
The SALSA guidelines recommend using BWA or BOWTIE2 aligner to map
reads.

``` bash
bowtie2 -x /PATH/INDEX \ -1 /PATH/Read1.fastq \ -2 /PATH/Read.fastq \ -S /PATH/Oct21_HiC.sam
```

**Sam to Bam file conversion**

The code below was run to convert .sam to .bam and the head command was
used to double check the first few lines of data

``` bash
samtools view -S -b -h Oct21_HiC.sam > OCt21_HiC.bam #to convert sam file to bam file
samtools view Oct21_HiC.bam | head # to check first few lines of bam file
```

**BamToBed conversion**

SALSA requires bed file as the input but this mapping generates a .bam
file so we need to convert to .bed. This can be done using the bamToBed
command from the Bedtools package. Additionally, SALSA requires bed file
to be sorted by the read name, rather than the alignment coordinates.
Once you have bam file, you can run following commands to get the bam
file needed as an input to SALSA.

``` bash
bamToBed -i Oct21_HiC.bam > Oct21_HiC.bed
sort -k 4 Oct21_HiC.bed > tmp && mv tmp Oct21_HiC.bed
```

### 2.2 Generating contig lengths file

SALSA requires contig lengths as an input. You can generate this file
using this command on your contig sequence file.

``` bash
samtools faidx contigs.fasta
This will generate contigs.fasta.fai as an input for -l option. You can use this file for contig lengths while running SALSA.
```

## 3.0 Run pipeline

The pipeline can be run with different input files depending on your
data.

### 3.1 I have contig sequences and the alignment bam file

This is the minimum input you will require Suppose you only have contig
sequences generated. Once you prepare the bed file as described above,
the code can be run as follows:

``` bash
python run_pipeline.py -a contigs.fasta -l contigs.fasta.fai -b Oct21_HiC.bed -e {G^ANTC,T^TAA,C^TNAG,^GATC} -o scaffolds 
```
