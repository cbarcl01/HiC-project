---
title: "HiC sequencing analysis pipeline"
author: "Charlotte Barclay"
date: "23/10/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This document includes instructions for set up and running of analysis pipeline for chromosome scale assembly of Mnemiopsis leidyi through the addition of HiC data.

### 1.1 Prepare environment

#### 1.1.1 Conda environment

In order to run the analysis, we need to make sure the relevant software is installed and packed. Using conda allows us too XXX 

```{bash, eval=FALSE}
#need to load miniconda first
module load miniconda3/4.6.14

#create environment with required parameters
conda create --prefix /arc/project/st-ssplotki-1/charlie/HiC_analysis python=2.7

#activate environment
source activate /arc/project/st-ssplotki-1/charlie/HiC_analysis

# add channels
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

# install software
conda install -c bioconda salsa2
```

Now the conda environment is set up, I need to prepare the environment by including the relevant tools. To start the scaffolding, I will need to map reads to the assembly using wither BWA or Bowtie2, however Salsa requires a bed file as input therefore I need to install both:

- BOWTIE2 or BWA
- Bedtools

**Code to install bowtie and bedtools** 

```{bash, eval=FALSE}
#create environment with required add ons
conda install -c bioconda samtools
conda install -c bioconda bowtie2
conda install -c bioconda bwa
conda install -c bioconda bedtools

```


Additionally I need a contig lengths file for input, for which I need to run samtools

**Code to install samtools**

```{bash, eval=FALSE}
conda install -c bioconda samtools
```



#### 1.1.2 Folders and data storage

Sockeye will open in local area (cwl account). Sockeye has high-speed, low-latency access to various data storage filesystems for storing, processing and sharing of data.

All users are granted 50GB of **Home storage** ( /home/<cwl> ). Sockeye additionally provides **Project storage** ( /arc/project/<alloc-code> ) and **Scratch space** ( /scratch/<alloc-code> ). Project storage and Scratch space quotas are determined by your allocation.

Project storage is generally used for input data and computational results. Scratch space is generally used for computational I/O including temporary storage for both intermediate data and computational results.

```{bash, eval=FALSE}
#filepath to home storage with HiC data
/home/cbarcl01/21_Oct_HiC

#filepath to scratch space 
/scratch/st-ssplotki-1/charlie/HiC

#filepath to project, input data should go here:
/arc/project/st-ssplotki-1/HiC_analysis
/arc/project/st-ssplotki-1/HiC_analysis/input #for input files

```


Finally, as HiC experiments can use different restriction enzymes - and the enzyme frequency in the contigs is used to normalise HiC interaction frequency in SALSA - I need to specify the restriction enzymes. To specify multiple restriction enzymes these should be separated by a **comma, without space"". The restriction enzymes used were:

- HinfI G^ANTC
- MseI T^TAA
- DdeI C^TNAG
- DPNII ^GATC



### 1.2 Identify data 

I need a reference genome dataset to align the HiC data too. In future this will be the long read PacBio data generated by the lab. To test the workflow I will use the existing ref dataset available.


```{bash, eval=FALSE}
#copy reference genome
pscp -P 22 C:\Users\cbarc\OneDrive\Documents\LAB_OriginsOfMulticellularity\Data\AGCP01.1.fsa_nt.gz cbarcl01@sockeye.arc.ubc.ca:/scratch/st-ssplotki-1/charlie/HiC 

# unzip files
gzip -d AGCP01.1.fsa_nt.gz
gzip -d plotkin-mle_S3HiC_R1.fastq.gz
gzip -d plotkin-mle_S3HiC_R2.fastq.gz
```

The HiC data provided by Phase Genomics can be found at:

```{bash, eval=FALSE}
#Forward Reads
wget https://drive.google.com/file/d/1pVCpCCFNqcPvPrDaYarx31L5EPj0WWHx/view?usp=sharing

#Reverse Reads
wget https://drive.google.com/file/d/19HBc5SYJbBSVFu_0FG13YNT00On5nUrx/view?usp=sharing

```

**Input file locations**

For use on sockeye, the data has been stored at the following locations: 

```{bash, eval=FALSE}
#HiC reads
/arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R1.fastq #forward
/arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R2.fastq #reverse

#reference genome
/scratch/st-ssplotki-1/charlie/HiC/AGCP01.1.fsa_nt.fasta

#index for reference genome
/arc/project/st-ssplotki-1/charlie/HiC_analysis/output/

#job scheduler 
/arc/project/st-ssplotki-1/charlie/HiC_analysis/mle_index.pbs

```

For long term storage the data can be found on Drake:

```{bash, eval=FALSE}
#HiC reads
/arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R1.fastq #forward
/arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R2.fastq #reverse

#reference genome
/scratch/st-ssplotki-1/charlie/HiC/AGCP01.1.fsa_nt.fasta

```

### 1.3 Preliminary QC

#### 1.3.1 Paired end reads

As these are paired end files there must be the same number of reads. The code below will produce the number of reads for each file.As these are fastq files the s/4 is used as each read will have 4 pieces of information:

1. The sequence ID, begins with '@SEQ_ID' 
2. The raw sequence
3. The character '+' and optionally the squence identifier
4. The quality score


```{bash, eval=FALSE}
awk '{s++}END{print s/4}' ./data/plotkin-mle_S3HiC_R2.fastq

awk '{s++}END{print s/4}' ./data/plotkin-mle_S3HiC_R1.fastq

```

**Results**

|Forward|Reverse Read|
|-------------|-------------|
|69789521|69789521|

#### 1.3.2 Fast QC


## 2.0 Prepare input files

As described in the introduction, the pipeline starts with alignment of the data to the existing assembly.

### 2.1 Mapping Reads

To start the scaffolding, first step is to map reads to the assembly. The SALSA guidelines recommend using BWA or BOWTIE2 aligner to map reads. 

**Create an index**

```{bash, eval=FALSE}
#samtools faidx AGCP01.1.fsa_nt

bowtie2-build /scratch/st-ssplotki-1/charlie/HiC/AGCP01.1.fsa_nt /arc/project/st-ssplotki-1/charlie/HiC_analysis/output/

```


**Align to reference genome**

```{bash, eval=FALSE}
bowtie2 -x /home/cbarcl01/21_Oct_HiC/AGCP01.1.fsa_nt.fai \ -1 /arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R1.fastq \ -2 /arc/project/st-ssplotki-1/charlie/HiC_analysis/input/plotkin-mle_S3HiC_R2.fastq \ -S /arc/project/st-ssplotki-1/charlie/HiC_analysis/output/Oct21_HiC.sam
```

**Sam to Bam file conversion** 

The code below was run to convert .sam to .bam and the head command was used to double check the first few lines of data

```{bash, eval=FALSE}
samtools view -S -b -h Oct21_HiC.sam > OCt21_HiC.bam #to convert sam file to bam file
samtools view Oct21_HiC.bam | head # to check first few lines of bam file
```

**BamToBed conversion**

SALSA requires bed file as the input but this mapping generates a .bam file so we need to convert to .bed. This can be done using the bamToBed command from the Bedtools package. Additionally, SALSA requires bed file to be sorted by the read name, rather than the alignment coordinates. Once you have bam file, you can run following commands to get the bam file needed as an input to SALSA.


```{bash, eval=FALSE}
bamToBed -i Oct21_HiC.bam > Oct21_HiC.bed
sort -k 4 Oct21_HiC.bed > tmp && mv tmp Oct21_HiC.bed
```


### 2.2  Generating contig lengths file

SALSA requires contig lengths as an input. You can generate this file using this command on your contig sequence file.

```{bash, eval=FALSE}
samtools faidx /scratch/st-ssplotki-1/charlie/HiC/AGCP01.1.fsa_nt.fasta

This will generate contigs.fasta.fai as an input for -l option. This file can be used for contig lengths while running SALSA.
```


## 3.0 Run pipeline

The pipeline can be run in multiple different ways to provide different outputs and additionally is flexible for different input files depending on your data. Below is a description of the full parameters of the pipeline as well as how I will run the code for different scenarios. 

### 3.1 Running the code

*"The new version of SALSA has been designed to consider several use cases depending on the input. Some assemblers output assembly graph as well along with the contig sequences. We provide options to use different information provided by the assembly to use for the scaffolding. Here is the what input options look like"*

python run_pipeline.py -h
usage: run_pipeline.py [-h] -a ASSEMBLY -l LENGTH -b BED [-o OUTPUT]
                       [-c CUTOFF] [-g GFA] [-u UNITIGS] [-e ENZYME]
                       [-i ITER] [-x DUP] [-s EXP] [-m CLEAN]

SALSA Iterative Pipeline

optional arguments:
  -h, --help            show this help message and exit
  -a ASSEMBLY, --assembly ASSEMBLY
                        Path to initial assembly, headers must not contain ':'
  -l LENGTH, --length LENGTH
                        Length of contigs at start
  -b BED, --bed BED     Bed file of alignments sorted by read names
  -o OUTPUT, --output OUTPUT
                        Output directory to put results
  -c CUTOFF, --cutoff CUTOFF
                        Minimum contig length to scaffold, default=1000
  -g GFA, --gfa GFA     GFA file for assembly
  -e ENZYME, --enzyme ENZYME
                        Restriction Enzyme used for experiment
  -i ITER, --iter ITER  Number of iterations to run, default = 3
  -x DUP, --dup DUP     File containing duplicated contig information
  -s EXP, --exp EXP     Expected Genome size of the assembled genome
  -m CLEAN, --clean CLEAN
                        Set this option to "yes" if you want to find
                        misassemblies in input assembly
Mapping Reads

### 3.2 I have contig sequences and the alignment bam file

This is the minimum input you will require Suppose you only have contig sequences generated. Once you prepare the bed file as described above, the code can be run as follows:

```{bash, eval=FALSE}
python run_pipeline.py -a contigs.fasta -l contigs.fasta.fai -b Oct21_HiC.bed -e {G^ANTC,T^TAA,C^TNAG,^GATC} -o scaffolds 


```


# 3.2 Running the code


